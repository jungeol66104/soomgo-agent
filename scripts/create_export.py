"""Create a timestamped export package for sharing data with colleagues."""

import json
import csv
import shutil
from pathlib import Path
from datetime import datetime
from collections import Counter
from typing import List, Dict, Any

# Source paths
DATA_DIR = Path("data")
CHAT_LIST_FILE = DATA_DIR / "chat_list_master.jsonl"
MESSAGES_DIR = DATA_DIR / "messages"
MODELS_FILE = Path("src/models.py")

# Export root
EXPORT_ROOT = Path("export")


def create_export_directory() -> Path:
    """Create timestamped export directory."""
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    export_dir = EXPORT_ROOT / f"{timestamp}_export"

    # Create directory structure
    (export_dir / "data" / "messages").mkdir(parents=True, exist_ok=True)
    (export_dir / "analysis").mkdir(parents=True, exist_ok=True)

    return export_dir


def load_chat_list() -> List[Dict[str, Any]]:
    """Load all chats from master list."""
    chats = []
    with open(CHAT_LIST_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                chats.append(json.loads(line))
    return chats


def get_scraped_message_files() -> set:
    """Get all scraped message file IDs."""
    return set(f.stem.replace('chat_', '') for f in MESSAGES_DIR.glob('chat_*.jsonl'))


def analyze_message_stats(messages_dir: Path) -> Dict[str, Any]:
    """Analyze message statistics from scraped files."""
    stats = {
        'total_messages': 0,
        'total_conversations': 0,
        'messages_per_chat': [],
        'total_chars': 0,
        'messages_with_content': 0
    }

    for msg_file in messages_dir.glob('chat_*.jsonl'):
        message_count = 0
        chars_in_chat = 0

        with open(msg_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    message_count += 1
                    stats['total_messages'] += 1

                    msg = json.loads(line)
                    if msg.get('message'):
                        msg_len = len(msg['message'])
                        chars_in_chat += msg_len
                        stats['total_chars'] += msg_len
                        stats['messages_with_content'] += 1

        stats['total_conversations'] += 1
        stats['messages_per_chat'].append(message_count)

    # Calculate averages
    if stats['messages_per_chat']:
        stats['avg_messages_per_chat'] = round(sum(stats['messages_per_chat']) / len(stats['messages_per_chat']), 2)
        stats['min_messages_per_chat'] = min(stats['messages_per_chat'])
        stats['max_messages_per_chat'] = max(stats['messages_per_chat'])
    else:
        stats['avg_messages_per_chat'] = 0
        stats['min_messages_per_chat'] = 0
        stats['max_messages_per_chat'] = 0

    if stats['messages_with_content'] > 0:
        stats['avg_message_length'] = round(stats['total_chars'] / stats['messages_with_content'], 2)
    else:
        stats['avg_message_length'] = 0

    # Remove the raw list to keep JSON clean
    del stats['messages_per_chat']

    return stats


def analyze_completeness(chats: List[Dict], scraped_ids: set) -> Dict[str, Any]:
    """Analyze data completeness."""
    total_chats = len(chats)
    scraped_count = 0
    missing_chats = []

    for chat in chats:
        chat_id = str(chat['id'])
        if chat_id in scraped_ids:
            scraped_count += 1
        else:
            missing_chats.append({
                'id': chat['id'],
                'service': chat['service']['title'],
                'user_name': chat['user']['name'],
                'created_at': chat['created_at'],
                'updated_at': chat['updated_at']
            })

    completion_rate = round((scraped_count / total_chats * 100), 2) if total_chats > 0 else 0

    return {
        'total_chats': total_chats,
        'scraped_count': scraped_count,
        'missing_count': len(missing_chats),
        'completion_rate': completion_rate,
        'missing_chats': missing_chats
    }


def analyze_services(chats: List[Dict]) -> Dict[str, Any]:
    """Analyze service distribution."""
    services = Counter(chat['service']['title'] for chat in chats)
    total = len(chats)

    distribution = [
        {
            'service': service,
            'count': count,
            'percentage': round((count / total * 100), 2)
        }
        for service, count in services.most_common()
    ]

    return {
        'total_unique': len(services),
        'distribution': distribution
    }


def analyze_hiring(chats: List[Dict]) -> Dict[str, Any]:
    """Analyze hiring statistics."""
    hired = sum(1 for chat in chats if chat['quote']['is_hired'])
    not_hired = len(chats) - hired

    return {
        'hired_count': hired,
        'not_hired_count': not_hired,
        'hiring_rate': round((hired / len(chats) * 100), 2) if chats else 0
    }


def analyze_prices(chats: List[Dict]) -> Dict[str, Any]:
    """Analyze price statistics."""
    prices = [chat['quote']['price'] for chat in chats if chat['quote']['price'] > 0]

    if not prices:
        return {
            'min': 0,
            'max': 0,
            'avg': 0,
            'median': 0
        }

    sorted_prices = sorted(prices)
    median_idx = len(sorted_prices) // 2
    median = sorted_prices[median_idx] if len(sorted_prices) % 2 == 1 else (sorted_prices[median_idx - 1] + sorted_prices[median_idx]) / 2

    return {
        'min': min(prices),
        'max': max(prices),
        'avg': round(sum(prices) / len(prices), 2),
        'median': round(median, 2)
    }


def analyze_users(chats: List[Dict]) -> Dict[str, Any]:
    """Analyze user statistics."""
    total = len(chats)
    left = sum(1 for chat in chats if chat['user']['is_leaved'])
    banned = sum(1 for chat in chats if chat['user']['is_banned'])
    dormant = sum(1 for chat in chats if chat['user']['is_dormant'])

    return {
        'left_users': left,
        'left_percentage': round((left / total * 100), 2),
        'banned_users': banned,
        'banned_percentage': round((banned / total * 100), 2),
        'dormant_users': dormant,
        'dormant_percentage': round((dormant / total * 100), 2)
    }


def analyze_temporal(chats: List[Dict]) -> Dict[str, Any]:
    """Analyze temporal statistics."""
    if not chats:
        return {
            'created_at_range': {'oldest': None, 'newest': None},
            'updated_at_range': {'oldest': None, 'newest': None},
            'date_range_span_days': None
        }

    created_dates = [chat['created_at'] for chat in chats]
    updated_dates = [chat['updated_at'] for chat in chats]

    # Calculate span for updated_at (to verify filtering)
    from datetime import datetime
    oldest_update = datetime.fromisoformat(min(updated_dates))
    newest_update = datetime.fromisoformat(max(updated_dates))
    updated_span_days = (newest_update - oldest_update).days

    return {
        'created_at_range': {
            'oldest': min(created_dates),
            'newest': max(created_dates)
        },
        'updated_at_range': {
            'oldest': min(updated_dates),
            'newest': max(updated_dates)
        },
        'updated_at_span_days': updated_span_days
    }


def generate_data_summary(chats: List[Dict], completeness: Dict, message_stats: Dict) -> Dict[str, Any]:
    """Generate high-level summary."""
    services = analyze_services(chats)
    hiring = analyze_hiring(chats)
    temporal = analyze_temporal(chats)

    return {
        'generated_at': datetime.now().isoformat(),
        'dataset_info': {
            'total_chats': completeness['total_chats'],
            'messages_scraped': completeness['scraped_count'],
            'completion_rate': completeness['completion_rate'],
            'missing_count': completeness['missing_count']
        },
        'filter_info': {
            'description': 'Chats filtered by updated_at (last activity)',
            'updated_at_range': f"{temporal['updated_at_range']['oldest']} to {temporal['updated_at_range']['newest']}" if temporal['updated_at_range']['oldest'] else None,
            'updated_at_span_days': temporal['updated_at_span_days']
        },
        'top_insights': {
            'most_common_service': services['distribution'][0]['service'] if services['distribution'] else None,
            'hiring_rate': hiring['hiring_rate'],
            'created_at_range': f"{temporal['created_at_range']['oldest']} to {temporal['created_at_range']['newest']}" if temporal['created_at_range']['oldest'] else None,
            'total_messages': message_stats['total_messages'],
            'avg_messages_per_chat': message_stats['avg_messages_per_chat']
        }
    }


def generate_data_overview(chats: List[Dict], completeness: Dict, message_stats: Dict) -> Dict[str, Any]:
    """Generate detailed overview."""
    return {
        'generated_at': datetime.now().isoformat(),
        'completeness': completeness,
        'services': analyze_services(chats),
        'hiring_stats': analyze_hiring(chats),
        'price_stats': analyze_prices(chats),
        'user_stats': analyze_users(chats),
        'temporal_stats': analyze_temporal(chats),
        'message_stats': message_stats
    }


def save_csv_exports(export_dir: Path, chats: List[Dict], completeness: Dict):
    """Generate CSV files for Excel analysis."""
    analysis_dir = export_dir / "analysis"

    # 1. Services breakdown CSV
    services = analyze_services(chats)
    with open(analysis_dir / "services_breakdown.csv", 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=['service', 'count', 'percentage'])
        writer.writeheader()
        writer.writerows(services['distribution'])

    # 2. Missing chats CSV
    if completeness['missing_chats']:
        with open(analysis_dir / "missing_chats.csv", 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=['id', 'service', 'user_name', 'created_at', 'updated_at'])
            writer.writeheader()
            writer.writerows(completeness['missing_chats'])

    # 3. Full chat list export CSV (flattened)
    with open(analysis_dir / "chat_list_export.csv", 'w', newline='', encoding='utf-8') as f:
        fieldnames = [
            'chat_id', 'service', 'user_name', 'user_address', 'price', 'is_hired',
            'created_at', 'updated_at', 'is_favorite', 'new_message_count',
            'provider_message_count', 'user_is_leaved', 'user_is_banned', 'user_is_dormant'
        ]
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()

        for chat in chats:
            writer.writerow({
                'chat_id': chat['id'],
                'service': chat['service']['title'],
                'user_name': chat['user']['name'],
                'user_address': chat['user']['address'],
                'price': chat['quote']['price'],
                'is_hired': chat['quote']['is_hired'],
                'created_at': chat['created_at'],
                'updated_at': chat['updated_at'],
                'is_favorite': chat['is_favorite'],
                'new_message_count': chat['new_message_count'],
                'provider_message_count': chat['provider_message_count'],
                'user_is_leaved': chat['user']['is_leaved'],
                'user_is_banned': chat['user']['is_banned'],
                'user_is_dormant': chat['user']['is_dormant']
            })


def create_readme(export_dir: Path, summary: Dict):
    """Create README for the export package."""
    readme_content = f"""# VF-Data ë°ì´í„° íŒ¨í‚¤ì§€

**ìƒì„± ì¼ì‹œ:** {summary['generated_at']}

## ë°ì´í„°ì…‹ ê°œìš”

- **ì „ì²´ ì±„íŒ… ìˆ˜:** {summary['dataset_info']['total_chats']}
- **ë©”ì‹œì§€ ìˆ˜ì§‘ ì™„ë£Œ:** {summary['dataset_info']['messages_scraped']}
- **ìˆ˜ì§‘ ì™„ë£Œìœ¨:** {summary['dataset_info']['completion_rate']}%
- **ê°€ì¥ ë§ì€ ì„œë¹„ìŠ¤:** {summary['top_insights']['most_common_service']}
- **ê³„ì•½ ì„±ì‚¬ìœ¨:** {summary['top_insights']['hiring_rate']}%
- **ì „ì²´ ë©”ì‹œì§€ ìˆ˜:** {summary['top_insights']['total_messages']}

## ë‚ ì§œ ë²”ìœ„

**ì¤‘ìš”:** ì´ ë°ì´í„°ì…‹ì€ ìµœê·¼ í™œë™ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§ë˜ì—ˆìŠµë‹ˆë‹¤.

- **ìƒì„± ë‚ ì§œ ë²”ìœ„:** {summary['top_insights']['created_at_range']}
  - ì±„íŒ…ì´ ì²˜ìŒ ìƒì„±ëœ ê¸°ê°„
- **ì—…ë°ì´íŠ¸ ë‚ ì§œ ë²”ìœ„ (í•„í„° ê¸°ì¤€):** {summary['filter_info']['updated_at_range']} ({summary['filter_info']['updated_at_span_days']}ì¼)
  - ì´ ê¸°ê°„ì— í™œë™ì´ ìˆì—ˆë˜ ì±„íŒ…ë§Œ í¬í•¨ë¨

## í¬í•¨ëœ íŒŒì¼

### ë°ì´í„° íŒŒì¼
- `data/chat_list_master.jsonl` - ì „ì²´ ì±„íŒ… ëª©ë¡ (í•œ ì¤„ì— í•˜ë‚˜ì”©)
- `data/messages/` - ê° ì±„íŒ…ì˜ ë©”ì‹œì§€ íŒŒì¼ë“¤ (`chat_<id>.jsonl`)

### ë¶„ì„ íŒŒì¼
- `analysis/data_summary.json` - í•µì‹¬ ìš”ì•½ í†µê³„
- `analysis/data_overview.json` - ìƒì„¸ í†µê³„ ë¶„ì„
- `analysis/services_breakdown.csv` - ì„œë¹„ìŠ¤ë³„ ë¶„í¬ (ì—‘ì…€ìš©)
- `analysis/chat_list_export.csv` - ì „ì²´ ì±„íŒ… ëª©ë¡ í…Œì´ë¸” í˜•ì‹ (ì—‘ì…€ìš©)
- `analysis/missing_chats.csv` - ë©”ì‹œì§€ê°€ ì—†ëŠ” ì±„íŒ… ëª©ë¡ (ìˆëŠ” ê²½ìš°)
- `analysis/missing_chats.json` - ìœ„ì™€ ë™ì¼ (JSON í˜•ì‹)

### ì½”ë“œ íŒŒì¼
- `models.py` - Pydantic ë°ì´í„° ëª¨ë¸ (ë°ì´í„° êµ¬ì¡° ì •ì˜)
- `requirements.txt` - Python ì˜ì¡´ì„± íŒ¨í‚¤ì§€

## ë°ì´í„° êµ¬ì¡°

### ì±„íŒ… ëª©ë¡ (`chat_list_master.jsonl`)
ê° ì¤„ì€ í•˜ë‚˜ì˜ ì±„íŒ…ì„ ë‚˜íƒ€ë‚´ëŠ” JSON ê°ì²´ì´ë©°, ë‹¤ìŒ í•„ë“œë¥¼ í¬í•¨í•©ë‹ˆë‹¤:
- `id` - ì±„íŒ… ID
- `service` - ì„œë¹„ìŠ¤ ì •ë³´
- `user` - ê³ ê° ì •ë³´
- `quote` - ê²¬ì /ê°€ê²© ì •ë³´
- `created_at`, `updated_at` - íƒ€ì„ìŠ¤íƒ¬í”„
- ê·¸ ì™¸... (ì „ì²´ ìŠ¤í‚¤ë§ˆëŠ” `models.py` ì°¸ê³ )

### ë©”ì‹œì§€ (`data/messages/chat_<id>.jsonl`)
ê° ì¤„ì€ í•˜ë‚˜ì˜ ë©”ì‹œì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” JSON ê°ì²´ì´ë©°, ë‹¤ìŒ í•„ë“œë¥¼ í¬í•¨í•©ë‹ˆë‹¤:
- `id` - ë©”ì‹œì§€ ID
- `user` - ë°œì‹ ì ì •ë³´
- `type` - ë©”ì‹œì§€ íƒ€ì… (TEXT, SYSTEM ë“±)
- `message` - ë©”ì‹œì§€ ë‚´ìš©
- `created_at` - íƒ€ì„ìŠ¤íƒ¬í”„
- ê·¸ ì™¸... (ì „ì²´ ìŠ¤í‚¤ë§ˆëŠ” `models.py` ì°¸ê³ )

## ë¹ ë¥¸ ì‹œì‘

### 1. ì˜ì¡´ì„± ì„¤ì¹˜
```bash
pip install -r requirements.txt
```

### 2. ë°ì´í„° ë¡œë“œ (Python)
```python
import json
from pathlib import Path

# ì±„íŒ… ëª©ë¡ ë¡œë“œ
chats = []
with open('data/chat_list_master.jsonl', 'r') as f:
    for line in f:
        chats.append(json.loads(line))

# íŠ¹ì • ì±„íŒ…ì˜ ë©”ì‹œì§€ ë¡œë“œ
chat_id = 158837874
messages = []
with open(f'data/messages/chat_{{chat_id}}.jsonl', 'r') as f:
    for line in f:
        messages.append(json.loads(line))
```

### 3. Pydantic ëª¨ë¸ ì‚¬ìš© (íƒ€ì… ì•ˆì „)
```python
from models import ChatItem, MessageItem

# ê²€ì¦ê³¼ í•¨ê»˜ íŒŒì‹±
chat = ChatItem(**chats[0])
print(chat.service.title)
print(chat.quote.price)
```

## ë¶„ì„ íŒŒì¼ í™œìš©

CSV íŒŒì¼ì„ ì—‘ì…€/êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ì—´ì–´ ì‰½ê²Œ íƒìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- `services_breakdown.csv` - ì„œë¹„ìŠ¤ë³„ ë¶„í¬ í™•ì¸
- `chat_list_export.csv` - ì „ì²´ ë°ì´í„°ë¥¼ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ í˜•ì‹ìœ¼ë¡œ

ë˜ëŠ” JSON íŒŒì¼ì„ í”„ë¡œê·¸ë˜ë° ë°©ì‹ìœ¼ë¡œ ì½ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- `data_summary.json` - ë¹ ë¥¸ ê°œìš”
- `data_overview.json` - ìƒì„¸ í†µê³„

## ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”?

ì „ì²´ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜ëŠ” `models.py`ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.
"""

    with open(export_dir / "README.md", 'w', encoding='utf-8') as f:
        f.write(readme_content)


def create_requirements_txt(export_dir: Path):
    """Create requirements.txt file."""
    requirements = """# VF-Data Export Dependencies

pydantic>=2.12.3
python-dotenv>=1.2.1
"""

    with open(export_dir / "requirements.txt", 'w', encoding='utf-8') as f:
        f.write(requirements)


def main():
    """Create export package."""
    print("=" * 60)
    print("Creating Export Package")
    print("=" * 60)

    # Create export directory
    print("\n1. Creating export directory...")
    export_dir = create_export_directory()
    print(f"   âœ“ Created: {export_dir}")

    # Copy data files
    print("\n2. Copying data files...")
    shutil.copy2(CHAT_LIST_FILE, export_dir / "data" / "chat_list_master.jsonl")
    print(f"   âœ“ Copied chat list")

    # Copy message files
    message_files = list(MESSAGES_DIR.glob("chat_*.jsonl"))
    for msg_file in message_files:
        shutil.copy2(msg_file, export_dir / "data" / "messages" / msg_file.name)
    print(f"   âœ“ Copied {len(message_files)} message files")

    # Load and analyze data
    print("\n3. Analyzing data...")
    chats = load_chat_list()
    scraped_ids = get_scraped_message_files()
    completeness = analyze_completeness(chats, scraped_ids)
    print(f"   âœ“ Analyzed {len(chats)} chats")

    # Analyze messages
    print("\n4. Analyzing messages...")
    message_stats = analyze_message_stats(export_dir / "data" / "messages")
    print(f"   âœ“ Analyzed {message_stats['total_messages']} messages")

    # Generate summaries
    print("\n5. Generating summary files...")
    summary = generate_data_summary(chats, completeness, message_stats)
    overview = generate_data_overview(chats, completeness, message_stats)

    with open(export_dir / "analysis" / "data_summary.json", 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)

    with open(export_dir / "analysis" / "data_overview.json", 'w', encoding='utf-8') as f:
        json.dump(overview, f, indent=2, ensure_ascii=False)

    if completeness['missing_chats']:
        with open(export_dir / "analysis" / "missing_chats.json", 'w', encoding='utf-8') as f:
            json.dump(completeness['missing_chats'], f, indent=2, ensure_ascii=False)

    print(f"   âœ“ Created JSON summaries")

    # Generate CSV exports
    print("\n6. Generating CSV files...")
    save_csv_exports(export_dir, chats, completeness)
    print(f"   âœ“ Created CSV exports")

    # Copy models.py
    print("\n7. Copying models.py...")
    shutil.copy2(MODELS_FILE, export_dir / "models.py")
    print(f"   âœ“ Copied models.py")

    # Create documentation
    print("\n8. Creating documentation...")
    create_readme(export_dir, summary)
    create_requirements_txt(export_dir)
    print(f"   âœ“ Created README.md and requirements.txt")

    # Print summary
    print("\n" + "=" * 60)
    print("Export Package Created!")
    print("=" * 60)
    print(f"\nğŸ“¦ Location: {export_dir}")
    print(f"\nğŸ“Š Summary:")
    print(f"   â€¢ Total chats: {completeness['total_chats']}")
    print(f"   â€¢ Messages scraped: {completeness['scraped_count']}")
    print(f"   â€¢ Completion rate: {completeness['completion_rate']}%")
    print(f"   â€¢ Total messages: {message_stats['total_messages']}")
    print(f"   â€¢ Avg messages/chat: {message_stats['avg_messages_per_chat']}")

    if completeness['missing_count'] > 0:
        print(f"\nâš ï¸  Missing {completeness['missing_count']} chat message files")
        print(f"   See: {export_dir / 'analysis' / 'missing_chats.json'}")

    print(f"\nâœ… Ready to share with colleagues!")


if __name__ == "__main__":
    main()
